{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2258a036-edcc-4203-a032-7fd4c75a16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076b685-d470-4ebb-98fe-89e831e0fa06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0893f489-550d-40d7-9ae8-c5a76a07eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54688e52-c01e-4889-946c-c3098c2ab22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_teducn_page_article_links(url,):\n",
    "    \"\"\"\n",
    "    Extracts all article links from a given teducn webpage.\n",
    "\n",
    "    This function scrapes the provided URL and extracts links to individual articles\n",
    "    found on the page.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL of the teducn webpage containing article links.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "            \"Links\": List[],\n",
    "            \"Message\": string,\n",
    "            \"Response\": int,\n",
    "            \"source_url\": string\n",
    "        }\n",
    "    Raises:\n",
    "    requests.RequestException: If there's an error fetching the webpage.\n",
    "    ValueError: If the expected HTML structure is not found on the page.\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'accept-encoding': 'gzip, deflate',\n",
    "        'accept-language': 'en-US,en;q=0.9,en-IN;q=0.8',\n",
    "        'cache-control': 'max-age=0',\n",
    "        'connection': 'keep-alive',\n",
    "        'cookie': 'rhldeecookieinforecord=%2C168-99%2C',\n",
    "        'host': 'www.teducn.com',\n",
    "        'if-modified-since': '{modified_since}',\n",
    "        'if-none-match': '{etag}',\n",
    "        'referer': '{referer}',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36 Edg/129.0.0.0'\n",
    "    }\n",
    "    final_response = {\n",
    "        \"Links\": [],\n",
    "        \"Message\": \"Success\",\n",
    "        \"Response\": 200,\n",
    "        \"source_url\": url\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = requests.get(url, headers=headers, timeout=(5, 60-5))\n",
    "        response.raise_for_status()\n",
    "        end_time = time.time()\n",
    "\n",
    "        if end_time-start_time > 50:\n",
    "            print(f\"This ULR Took more then 50s: {url}\")\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # # Getting all the links of articles \n",
    "        all_links = []\n",
    "        article_block = soup.find(\"td\", class_=\"down_list\")\n",
    "        if article_block:\n",
    "            for each_head in article_block:\n",
    "                article_links = each_head.find_all(\"a\")\n",
    "                if article_links:\n",
    "                    for each_link in article_links:\n",
    "                        full_url = each_link.get(\"href\")\n",
    "                        all_links.append(full_url)\n",
    "                        \n",
    "        final_response[\"Links\"] = all_links\n",
    "        return final_response\n",
    "     \n",
    "    except requests.Timeout:\n",
    "        final_response[\"Message\"] = \"Request timed out\"\n",
    "        final_response[\"Response\"] = 408  # Request Timeout\n",
    "        return final_response\n",
    "    except requests.RequestException as e:\n",
    "        # print(f\"An error occurred while fetching the webpage: {e}\")\n",
    "        final_response[\"Message\"] = f\"An error occurred while fetching the webpage: {e}\"\n",
    "        final_response[\"Response\"] = getattr(e.response, 'status_code', None)\n",
    "        return final_response\n",
    "    except ValueError as e:\n",
    "        # print(f\"An error occurred while parsing the webpage: {e}\")\n",
    "        final_response[\"Message\"] = f\"An error occurred while parsing the webpage: {e}\"\n",
    "        final_response[\"Response\"] = 404\n",
    "        # getattr(e.response, 'status_code', None)\n",
    "        return final_response\n",
    "    except Exception as e:\n",
    "        # print(f\"An unexpected error occurred: {e}\")\n",
    "        final_response[\"Message\"] = f\"An unexpected error occurred: {e}\"\n",
    "        final_response[\"Response\"] = 500\n",
    "        return final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bb97c0-397e-413e-91b6-0d168800449c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed414892-9c45-4db7-a9ae-e56ac4b3775e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c598f0ac-0079-4ccf-a24e-e552628cd629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Links': ['http://www.teducn.com/renwu/dashihuicui/2013-10-09/838.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2013-03-27/831.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/554.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/553.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/552.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/551.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/550.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/549.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/548.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/547.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/546.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/545.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/544.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/543.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/542.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/541.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/540.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/539.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/538.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/537.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/536.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/535.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/534.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/533.html',\n",
       "  'http://www.teducn.com/renwu/dashihuicui/2011-05-16/532.html'],\n",
       " 'Message': 'Success',\n",
       " 'Response': 200,\n",
       " 'source_url': 'http://www.teducn.com/renwu/dashihuicui/'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.teducn.com/renwu/dashihuicui/\"\n",
    "# url = \"http://www.teducn.com/fagui/difangfagui/\"\n",
    "\n",
    "extract_teducn_page_article_links(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a22674e-af54-45c3-9667-75be1ce42357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efae0e1-4c58-41bc-8643-fe002b6ca33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21818ac-8d79-49c1-bf14-2c5866b811ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def requests_retry_session(\n",
    "    retries=3,\n",
    "    backoff_factor=0.3,\n",
    "    status_forcelist=(500, 502, 504),\n",
    "    session=None,\n",
    "):\n",
    "    session = session or requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "\n",
    "def scrape_teducn_article_content(url, tags):\n",
    "    headers = {\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'accept-encoding': 'gzip, deflate',\n",
    "        'accept-language': 'en-US,en;q=0.9,en-IN;q=0.8',\n",
    "        'cache-control': 'max-age=0',\n",
    "        'connection': 'keep-alive',\n",
    "        'cookie': 'rhldeecookieinforecord=%2C168-99%2C',\n",
    "        'host': 'www.teducn.com',\n",
    "        'if-modified-since': '{modified_since}',\n",
    "        'if-none-match': '{etag}',\n",
    "        'referer': '{referer}',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36 Edg/129.0.0.0'\n",
    "    }\n",
    "    \n",
    "    final_response = {\n",
    "        \"data\": {\n",
    "            'title': \"\",\n",
    "            'body': {\"Audio\": \"\", \"Text\": []},\n",
    "            'meta_data': {'URL': url, 'Author': \"\", 'Date': \"\", 'Tags': [tags]}\n",
    "        },\n",
    "        \"Message\": \"Success\",\n",
    "        \"Response\": 200\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Add a random delay before making the request\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "        \n",
    "        # Make the request to the URL using the retry session\n",
    "        session = requests_retry_session()\n",
    "        response = session.get(url, headers=headers, allow_redirects=False)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Check for redirect\n",
    "        if response.is_redirect:\n",
    "            final_response[\"Message\"] = f\"Redirected to: {response.headers['Location']}\"\n",
    "            final_response[\"Response\"] = response.status_code\n",
    "            return final_response\n",
    "        \n",
    "        # Parse the page content with BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the specific table\n",
    "        tags_table = soup.find('table', attrs={\n",
    "            'width': '100%',\n",
    "            'border': '0',\n",
    "            'cellpadding': '2',\n",
    "            'cellspacing': '1',\n",
    "            'bgcolor': '#DBF3FF'\n",
    "            })\n",
    "        print(tags_table)\n",
    "        if tags_table:\n",
    "            links = tags_table.find_all('a')\n",
    "            # Extract href and text from each link\n",
    "            extracted_links = [link.get_text(strip=True) for link in links]\n",
    "            print(extracted_links)\n",
    "            final_response['data']['meta_data'][\"Tags\"] = extracted_links \n",
    "\n",
    "        # Find the specific table\n",
    "        table = soup.find('table', class_='title_info')\n",
    "        print(table)\n",
    "        if table:\n",
    "        \n",
    "            # Extract title\n",
    "            title_span = table.find('span', class_='lan_19')\n",
    "            title = title_span.get_text(strip=True) if title_span else None\n",
    "            \n",
    "            # Extract date and author/source\n",
    "            info_td = table.find('td', class_='hei_zw')\n",
    "            if info_td:\n",
    "                info_text = info_td.get_text(strip=True)\n",
    "                \n",
    "                # Extract date\n",
    "                date_match = re.search(r'སྤེལ་དུས།(\\d{2}-\\d{2})', info_text)\n",
    "                date = date_match.group(1) if date_match else None\n",
    "                \n",
    "                # Extract author and source\n",
    "                author_source = re.sub(r'སྤེལ་དུས།\\d{2}-\\d{2}', '', info_text).strip()\n",
    "                author_source = re.sub(r'ཡོང་ཁུངས།|རྩོམ་པ་པོ།', '', author_source).strip()\n",
    "            else:\n",
    "                date = None\n",
    "                author_source = None\n",
    "\n",
    "            final_response['data'][\"title\"] = title\n",
    "            final_response['data']['meta_data'][\"Author\"] = author_source\n",
    "            final_response['data']['meta_data'][\"Date\"] = date\n",
    "            \n",
    "       # Extract body content\n",
    "        try:\n",
    "            body = soup.find(\"span\", class_=\"txt\")\n",
    "            if body:\n",
    "                # Extract all text content, including spans\n",
    "                all_text = body.find_all(string=True)\n",
    "                \n",
    "                # Filter out empty strings and strip whitespace\n",
    "                filtered_text = [text.strip() for text in all_text if text.strip()]\n",
    "                \n",
    "                # Remove duplicate consecutive lines (which often occur due to formatting)\n",
    "                final_text = []\n",
    "                for line in filtered_text:\n",
    "                    if not final_text or line != final_text[-1]:\n",
    "                        final_text.append(line)\n",
    "                \n",
    "                final_response['data']['body'][\"Text\"] = final_text\n",
    "            else:\n",
    "                final_response['data']['body'][\"Text\"] = [\"\"]\n",
    "        except AttributeError as e:\n",
    "            final_response['data']['body'][\"Text\"] = [f\"Error fetching body content: {str(e)}\"]\n",
    "        \n",
    "        return final_response\n",
    "    except requests.Timeout:\n",
    "        final_response[\"Message\"] = \"Request timed out\"\n",
    "        final_response[\"Response\"] = 408  # Request Timeout\n",
    "        return final_response\n",
    "    except requests.RequestException as e:\n",
    "        final_response[\"Message\"] = f\"An error occurred while fetching the article: {str(e)}\"\n",
    "        final_response[\"Response\"] = getattr(e.response, 'status_code', 500)\n",
    "        return final_response\n",
    "    except Exception as e:\n",
    "        final_response[\"Message\"] = f\"An unexpected error occurred: {e}\"\n",
    "        final_response[\"Response\"] = 500\n",
    "        return final_response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdfb3728-4a39-47e2-ab9a-79534a299fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table bgcolor=\"#DBF3FF\" border=\"0\" cellpadding=\"2\" cellspacing=\"1\" width=\"100%\">\n",
      "<tr>\n",
      "<td bgcolor=\"#F0FBFF\" height=\"30\"><span class=\"lan_22\">ད་སྔ་གཟིགས་བཞིན་པ། <a href=\"http://www.teducn.com/index.php\"> མདུན་ངོས།</a> &gt; <a href=\"http://www.teducn.com/renwu/\">མི་སྣ་མཚམས་སྦྱོར།</a> &gt; <a href=\"http://www.teducn.com/renwu/xiandairenwu/\">དེང་རབས་གྲགས་ཅན།</a></span></td>\n",
      "</tr>\n",
      "</table>\n",
      "['མདུན་ངོས།', 'མི་སྣ་མཚམས་སྦྱོར།', 'དེང་རབས་གྲགས་ཅན།']\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"title_info\" width=\"100%\">\n",
      "<tr>\n",
      "<td><span class=\"lan_19\">༄༅། །དེང་རབས་བོད་ཀྱི་རྩོམ་རིག་གི་མཁའ་དབྱིངས་སུ་རྟག་ཏུ་འཚེར་བའི་སྐར་མ་འོད་ཆེན་ཏེ་དཔལ་དོན་གྲུབ་རྒྱལ།</span></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"hei_zw\">སྤེལ་དུས།04-27  ཡོང་ཁུངས།  རྩོམ་པ་པོ།</td>\n",
      "</tr>\n",
      "</table>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': {'title': '༄༅། །དེང་རབས་བོད་ཀྱི་རྩོམ་རིག་གི་མཁའ་དབྱིངས་སུ་རྟག་ཏུ་འཚེར་བའི་སྐར་མ་འོད་ཆེན་ཏེ་དཔལ་དོན་གྲུབ་རྒྱལ།',\n",
       "  'body': {'Audio': '',\n",
       "   'Text': ['དཔལ་དོན་གྲུབ་རྒྱལ་ནི་༡༩༥༣ལོར་མཚོ་སྔོན་ཞིང་ཆེན་རྨ་ལྷོ་བོད་རིགས་རང་སྐྱོང་ཁུལ་གཅན་ཚ་རྫོང་དགུ་རོང་སྡེ་བར་འཁྲུངས།༡༩༦༡ལོར་དཔལ་དོན་གྲུབ་རྒྱལ་ལོ་བརྒྱད་ལ་སླེབས་ཤིང་། ཕ་ཡུལ་གྱི་སློབ་ཆུང་དུ་ཞུགས་ནས་སློབ་སྦྱོང་བྱེད་པའི་མགོ་བརྩམས།\\xa0 ༡༩༦༤ལོར་རྨ་ལྷོ་ཁུལ་དགེ་འོས་སློབ་གྲྭར་ཞུགས་ཤིང་སློབ་མཐར་ཕྱིན་ཏེ། མཚོ་སྔོན་མི་དམངས་ཀུན་ཁྱབ་རླུང་འཕྲིན་ལས་ཁུངས་སུ་ལས་ཀར་ཞུགས། ༡༩༧༡ལོར་ཀྲུང་དབྱངས་མི་རིགས་སློབ་གླིང་སྐད་ཡིག་རྩོམ་རིག་ཚན་ཁག་གི་བོད་རྒྱའི་ཡིག་བསྒྱུར་ཆེད་ལས་སུ་ཞུགས་ཏེ་སློབ་སྦྱོང་བྱས་ཤིང་། ༡༩༧༥ལོར་མཐར་ཕྱིན་ནས་ཕྱིར་མཚོ་སྔོན་མི་དམངས་ཀུན་ཁྱབ་རླུང་འཕྲིན་ལས་ཁུངས་ལ་ལོག་སྟེ་ཕྱག་ལས་གནང་།\\xa0 ༡༩༧༨ལོར་ཀྲུང་དབྱངས་མི་རིགས་སློབ་གླིང་བོད་ཀྱི་རྩོམ་རིག་ཆེད་ལས་ཀྱི་ཞིབ་འཇུག་སློབ་མར་རྒྱུགས་སྤྲད་ནས་འཕྲོད་ཅིང་། མཁས་དབང་དུང་དཀར་བློ་བཟང་འཕྲིན་ལས་མཆོག་དགེ་རྒན་དུ་བསྟེན་ནས་བོད་ཀྱི་རིག་གཞུང་སྤྱི་དང་ཁྱད་པར་དུ་གནའ་རབས་བོད་ཀྱི་རྩོམ་རིག་ལ་སྦྱངས་བརྩོན་མཛད།\\xa0 ཁོང་གི་སྦྱངས་འབྲས་ལེགས་ཤིང་རྣམ་དཔྱོད་ཕུལ་དུ་བྱུང་བར་མཁས་དབང་དུང་དཀར་བློ་བཟང་འཕྲིན་ལས་མཆོག་གིས་ཀྱང་བསྟོད་བསྔགས་དང་གཙིགས་ཆེན་མཛད་ལ།\\xa0 ༡༩༨༡ལོར་',\n",
       "    '《',\n",
       "    'བོད་ཀྱི་མགུར་གླུའི་བྱུང་འཕེལ་གྱི་ལོ་རྒྱུས་དང་ཁྱད་ཆོས་རིག་པའི་ཁྱེའུ་རྣམ་པར་རྩེན་པའི་སྐྱེད་ཚལ་',\n",
       "    '》',\n",
       "    'ཞེས་པའི་དཔྱད་རྩོམ་བྲིས་ནས་ཧྲོ་ཧྲིའི་མིང་བཏགས་བླངས་ཤིང་སློབ་གྲྭ་དེར་དགེ་རྒན་གྱི་ཕྱག་ལས་གནང་། ༡༩༨༣ལོར་མཚོ་སྔོན་ཞིང་ཆེན་ཆབ་ཆ་གྲོང་རྡལ་དུ་ཡོད་པའི་མཚོ་ལྷོ་ཁུལ་མི་རིགས་དགེ་འོས་སློབ་གྲྭར་ཕེབས་ནས་དགེ་རྒན་གྱི་ལས་ཀ་མཛད།\\xa0 སྐབས་དེར་ཁྱིམ་དུ་བདེ་སྐྱིད་ཀྱི་དྲོད་ཁོལ་ཞན་པ་དང་ཕ་མའི་བྱམས་སྐྱོང་གི་ནུ་ཞོ་རེག་མ་ཐུབ་པའི་ཁར་',\n",
       "    '《',\n",
       "    'སྤྲུལ་སྐུ',\n",
       "    '》',\n",
       "    'སོགས་གསར་རྩོམ་བྱས་ཏེ་སྐབས་དེའི་བོད་ཀྱི་སྤྱི་ཚོགས་ཀྱི་དོན་དངོས་ལ་ཟུར་ཟ་བྱས་སྟབས།\\xa0 སྲོལ་རྒྱུན་གྱི་སྡང་མིག་དང་སྤྱི་ཚོགས་ཀྱི་གླེང་ཕྱོགས་བཅས་ནི་ཤིན་ཏུ་ཐེག་དཀའ་བའི་ཁུར་བོ་ཞིག་ཏུ་གྱུར་ཀྱང་། དཀའ་སྡུག་དང་འགལ་ཟླ་ལ་མགོ་མི་སྒུར་བ་ནི་ཁོའི་ཞུམ་པ་མེད་པའི་སྙིང་སྟོབས་དང་སྤོབས་པ་རེད།',\n",
       "    '༡༩༨༥ལོའི་ཟླ་༡༡པའི་ཚེས་༢༩ཉིན་རྩོམ་རིག་གསར་རྩོམ་དང་རིག་གཞུང་ཞིབ་འཇུག་ལ་གསེར་ལྟར་དཀོན་པའི་མཁས་དབང་འདི་ཉིད་མཚོ་སྔོན་ཞིང་ཆེན་མཚོ་ལྷོ་ཁུལ་ཆབ་ཆ་གྲོང་རྡལ་དུ་དགུང་ལོ་སོ་གཉིས་སྟེང་སྐུ་གཤེགས་པས་འདི་ནི་བོད་ཀྱི་རྩོམ་རིག་གསར་བའི་གར་སྟེགས་སྟེང་གི་གོད་ཆག་ཅིག་ཏུ་གྱུར།\\xa0 ཉིན་དེར་ཁོང་གིས་ཡུན་རིང་རེ་སྒུག་བྱས་པའི་ཞན་ཡང་བོད་ལྗོངས་སློབ་གླིང་གི་ལས་གནས་སྤོར་བའི་གྲོས་ཡིག་འབྱོར་མོད་ཧ་ཅང་ཕངས་བའི་གནས་སུ་གྱུར།',\n",
       "    'དཔལ་དོན་གྲུབ་རྒྱལ་མཆོག་ནི་དེང་རབས་བོད་ཀྱི་རྩོམ་རིག་གི་མཁའ་དབྱིངས་སུ་རྟག་ཏུ་འཚེར་བའི་སྐར་མ་འོད་ཆེན་ཞིག་ཡིན་ཞིང་།\\xa0 ཁོང་གི་མི་ཚེའི་བརྒྱུད་རིམ་དང་བློ་གྲོས་ཀྱི་རྩལ་ནི་ཧ་ཅང་ཐུན་མོང་མ་ཡིན་པ་ཞིག་ཡིན་ལ། དེ་བཞིན་དུ་ཁོང་གི་རྩོམ་རིག་བརྩམས་ཆོས་ལའང་གསར་གཏོད་ཀྱི་རང་བཞིན་དང་ཐུན་མོང་མ་ཡིན་པའི་ཁྱད་ཆོས་ལྡན་པས།\\xa0 རིག་གཞུང་ཞིབ་འཇུག་ཐད་གྲུབ་འབྲས་མངོན་གསལ་བླངས་ཤིང་།\\xa0 བོད་ཀྱི་དེང་རབས་རྩོམ་རིག་གི་གར་སྟེགས་སྟེང་གསར་རྩོམ་གྱི་གར་སྟབས་ཐུན་མོང་མ་ཡིན་པ་ཞིག་བསྒྱུར་བ་དང་།\\xa0 ཁོའི་ཤིན་ཏུ་ཐུང་བའི་མི་ཚེའི་ཤོག་བྱང་ངོས་སུ་ཕུལ་དུ་བྱུང་བའི་རྩོམ་རིག་གི་གྲུབ་འབྲས་བླ་མེད་བསྐྲུན་པ་རེད།',\n",
       "    'ཁོང་གིས་བོད་ཡིག་གི་ལམ་ནས་བྲིས་པའི་རང་མོས་སྙན་ངག་དང་སྒྲུང་གཏམ།\\xa0 ལྷུག་རྩོམ་བཅས་ནི་ལོ་རབས་བརྒྱད་ཅུ་པའི་བོད་ཀྱི་དེང་རབས་རྩོམ་རིག་གི་སྒོ་འཕར་ཡངས་པོ་ཕྱེས་ལ།\\xa0 བོད་རིགས་ཀྱི་མཁས་པ་དང་རྩོམ་པ་པོ་ཀུན་གྱིས་གདེང་འཇོག་ཆེན་པོ་བྱས་ཡོད་པ་དང་།\\xa0 ཁོང་གིས་དེང་རབས་བོད་ཀྱི་རྩོམ་རིག་དང་རིག་གཞུང་གི་འཕེལ་རྒྱས་ལ་བྱས་རྗེས་ཆེན་པོ་བཞག་ཡོད་པས།\\xa0 བོད་ཀྱི་དེང་རབས་རྩོམ་རིག་གི་རྨང་གཞི་འདིང་མཁན་ཡིན་ཞེས་བརྗོད་ཆོག་ཆོག་ཡིན།',\n",
       "    '1',\n",
       "    '/',\n",
       "    '2',\n",
       "    '1',\n",
       "    '2',\n",
       "    '下一页',\n",
       "    '尾页']},\n",
       "  'meta_data': {'URL': 'http://www.teducn.com/renwu/xiandairenwu/2011-04-27/516.html',\n",
       "   'Author': '',\n",
       "   'Date': '04-27',\n",
       "   'Tags': ['མདུན་ངོས།', 'མི་སྣ་མཚམས་སྦྱོར།', 'དེང་རབས་གྲགས་ཅན།']}},\n",
       " 'Message': 'Success',\n",
       " 'Response': 200}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.teducn.com/fagui/difangfagui/2010-05-20/168.html\"\n",
    "url = \"http://www.teducn.com/renwu/xiandairenwu/2011-04-27/516.html\"\n",
    "scrape_teducn_article_content(url, tags=\"དཔྱད་གཏམ།\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe349a6-67ab-49f1-bcba-871bfcb0d8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c1dfd-23c4-4748-b2b9-6f32437c4d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01d677-0fb7-401e-a10f-ce930692af97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6bffb0-13d2-4b11-952f-4122c7e2699b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
