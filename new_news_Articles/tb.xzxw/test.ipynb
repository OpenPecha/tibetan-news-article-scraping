{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2258a036-edcc-4203-a032-7fd4c75a16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076b685-d470-4ebb-98fe-89e831e0fa06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0893f489-550d-40d7-9ae8-c5a76a07eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54688e52-c01e-4889-946c-c3098c2ab22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tb_xzxw_page_article_links(url,):\n",
    "    \"\"\"\n",
    "    Extracts all article links from a given tb_xzxw webpage.\n",
    "\n",
    "    This function scrapes the provided URL and extracts links to individual articles\n",
    "    found on the page.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL of the tb_xzxw webpage containing article links.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "            \"Links\": List[],\n",
    "            \"Message\": string,\n",
    "            \"Response\": int,\n",
    "            \"source_url\": string\n",
    "        }\n",
    "    Raises:\n",
    "    requests.RequestException: If there's an error fetching the webpage.\n",
    "    ValueError: If the expected HTML structure is not found on the page.\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    final_response = {\n",
    "        \"Links\": [],\n",
    "        \"Message\": \"Success\",\n",
    "        \"Response\": 200,\n",
    "        \"source_url\": url\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = requests.get(url, headers=headers, timeout=(5, 60-5))\n",
    "        response.raise_for_status()\n",
    "        end_time = time.time()\n",
    "\n",
    "        if end_time-start_time > 50:\n",
    "            print(f\"This ULR Took more then 50s: {url}\")\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # # Getting all the links of articles \n",
    "        all_links = []\n",
    "        all_link_article = soup.find(\"div\", class_=\"sj_left_list\")\n",
    "        if all_link_article:\n",
    "            article_block = all_link_article.find_all(\"div\", class_=\"sj_left_list_title\")\n",
    "            if article_block:\n",
    "                for each_head in article_block:\n",
    "                    article_links = each_head.find(\"a\")\n",
    "                    if article_links:\n",
    "                        full_url = article_links.get(\"href\")\n",
    "                        all_links.append(full_url)\n",
    "                        \n",
    "        final_response[\"Links\"] = all_links\n",
    "        return final_response\n",
    "     \n",
    "    except requests.Timeout:\n",
    "        final_response[\"Message\"] = \"Request timed out\"\n",
    "        final_response[\"Response\"] = 408  # Request Timeout\n",
    "        return final_response\n",
    "    except requests.RequestException as e:\n",
    "        # print(f\"An error occurred while fetching the webpage: {e}\")\n",
    "        final_response[\"Message\"] = f\"An error occurred while fetching the webpage: {e}\"\n",
    "        final_response[\"Response\"] = getattr(e.response, 'status_code', None)\n",
    "        return final_response\n",
    "    except ValueError as e:\n",
    "        # print(f\"An error occurred while parsing the webpage: {e}\")\n",
    "        final_response[\"Message\"] = f\"An error occurred while parsing the webpage: {e}\"\n",
    "        final_response[\"Response\"] = 404\n",
    "        # getattr(e.response, 'status_code', None)\n",
    "        return final_response\n",
    "    except Exception as e:\n",
    "        # print(f\"An unexpected error occurred: {e}\")\n",
    "        final_response[\"Message\"] = f\"An unexpected error occurred: {e}\"\n",
    "        final_response[\"Response\"] = 500\n",
    "        return final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bb97c0-397e-413e-91b6-0d168800449c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed414892-9c45-4db7-a9ae-e56ac4b3775e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c598f0ac-0079-4ccf-a24e-e552628cd629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Links': ['https://tb.xzxw.com/xw/2023-10/28/content_1008719.html',\n",
       "  'https://tb.xzxw.com/xw/2023-07/07/content_882731.html',\n",
       "  'https://tb.xzxw.com/xw/2020-03/25/content_3985606.html',\n",
       "  'https://tb.xzxw.com/xw/2015-05/12/content_1541114.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-03/25/content_1357984.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-03/13/content_1341228.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-03/06/content_1332382.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-12/22/content_1991297.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-12/01/content_1951546.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-11/27/content_1944380.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-10/23/content_1876566.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-09/01/content_1784719.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-08/11/content_1747846.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-07/28/content_1719414.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-07/24/content_1713759.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-07/22/content_1709310.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-07/10/content_1689724.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-07/10/content_1689719.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-06/26/content_1662979.html',\n",
       "  'https://tb.xzxw.com/kjws/2015-06/19/content_1651908.html'],\n",
       " 'Message': 'Success',\n",
       " 'Response': 200,\n",
       " 'source_url': 'https://tb.xzxw.com/kjws/node_25955.html'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://tb.xzxw.com/kjws/node_25955.html\"\n",
    "URL = \"https://tb.xzxw.com/wxys/node_25974.html\"\n",
    "extract_tb_xzxw_page_article_links(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a22674e-af54-45c3-9667-75be1ce42357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0efae0e1-4c58-41bc-8643-fe002b6ca33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ti.zangdiyg.com/category/index/id/61\n"
     ]
    }
   ],
   "source": [
    "# custom_url = 'https://ti.zangdiyg.com/category/index/id/61.html'\n",
    "# print(custom_url.replace(\".html\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da43a3c-fa6d-4017-aaf8-718649005b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ff984-7034-4f42-aadb-0ced1eff2de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd008b9d-206b-4170-8f45-d6bcb77e2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def requests_retry_session(\n",
    "    retries=3,\n",
    "    backoff_factor=0.3,\n",
    "    status_forcelist=(500, 502, 504),\n",
    "    session=None,\n",
    "):\n",
    "    session = session or requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session\n",
    "\n",
    "\n",
    "def scrape_tb_xzxw_article_content(url, tags):\n",
    "    headers = {\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "        'Accept-Language': 'en-US,en;q=0.9,en-IN;q=0.8',\n",
    "        'Cache-Control': 'max-age=0',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Cookie': 'sajssdk_2015_cross_new_user=1; sensorsdata2015jssdkcross=%7B%22distinct_id%22%3A%221921d97a9f3ed0-0af301c17e118f-4c657b58-1188554-1921d97a9f4bab%22%2C%22first_id%22%3A%22%22%2C%22props%22%3A%7B%22%24latest_traffic_source_type%22%3A%22%E7%9B%B4%E6%8E%A5%E6%B5%81%E9%87%8F%22%2C%22%24latest_search_keyword%22%3A%22%E6%9C%AA%E5%8F%96%E5%88%B0%E5%80%BC_%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%22%2C%22%24latest_referrer%22%3A%22%22%7D%2C%22identities%22%3A%22eyIkaWRlbnRpdHlfY29va2llX2lkIjoiMTkyMWQ5N2E5ZjNlZDAtMGFmMzAxYzE3ZTExOGYtNGM2NTdiNTgtMTE4ODU1NC0xOTIxZDk3YTlmNGJhYiJ9%22%2C%22history_login_id%22%3A%7B%22name%22%3A%22%22%2C%22value%22%3A%22%22%7D%2C%22%24device_id%22%3A%221921d97a9f3ed0-0af301c17e118f-4c657b58-1188554-1921d97a9f4bab%22%7D',\n",
    "        'Host': 'tb.xzxw.com',\n",
    "        'Referer': 'https://tb.xzxw.com/wxys/node_25972.html',\n",
    "        'Sec-Fetch-Dest': 'document',\n",
    "        'Sec-Fetch-Mode': 'navigate',\n",
    "        'Sec-Fetch-Site': 'same-origin',\n",
    "        'Sec-Fetch-User': '?1',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36 Edg/129.0.0.0',\n",
    "        'sec-ch-ua': '\"Microsoft Edge\";v=\"129\", \"Not=A?Brand\";v=\"8\", \"Chromium\";v=\"129\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-platform': '\"Windows\"'\n",
    "    }\n",
    "    \n",
    "    final_response = {\n",
    "        \"data\": {\n",
    "            'title': \"\",\n",
    "            'body': {\"Audio\": \"\", \"Text\": []},\n",
    "            'meta_data': {'URL': url, 'Author': \"\", 'Date': \"\", 'Tags': [tags]}\n",
    "        },\n",
    "        \"Message\": \"Success\",\n",
    "        \"Response\": 200\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Add a random delay before making the request\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "        \n",
    "        # Make the request to the URL using the retry session\n",
    "        session = requests_retry_session()\n",
    "        response = session.get(url, headers=headers, allow_redirects=False)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Check for redirect\n",
    "        if response.is_redirect:\n",
    "            final_response[\"Message\"] = f\"Redirected to: {response.headers['Location']}\"\n",
    "            final_response[\"Response\"] = response.status_code\n",
    "            return final_response\n",
    "        \n",
    "        # Parse the page content with BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        tags_body = soup.find(\"div\", class_=\"sj4_left_nav\")\n",
    "        tags = []\n",
    "        if tags_body:\n",
    "            tag_list = tags_body.find_all(\"a\")\n",
    "            if tag_list:\n",
    "                for tag in tag_list:\n",
    "                    each_tag = tag.get_text(strip=True)\n",
    "                    tags.append(each_tag)\n",
    "                final_response['data']['meta_data'][\"Tags\"] = tags\n",
    "        \n",
    "        full_body = soup.find('div', class_=\"sj4_left_list\")\n",
    "        if full_body:\n",
    "            # Extract title\n",
    "            title = full_body.find('p', class_=\"second_title\")\n",
    "            if title:\n",
    "                title_text = title.get_text(strip=True)\n",
    "            else:\n",
    "                title = full_body.find('p', class_=\"first_title\")\n",
    "                if title:\n",
    "                    title_text = title.get_text(strip=True)\n",
    "                else:\n",
    "                    title = full_body.find('p', class_=\"third_title\")\n",
    "                    if title:\n",
    "                        title_text = title.get_text(strip=True)\n",
    "                    else:\n",
    "                        title_text = \"\"\n",
    "            final_response['data'][\"title\"] = title_text\n",
    "            \n",
    "            metadata = full_body.find('span', class_=\"item_content\")\n",
    "            # Extracting Meta Data\n",
    "            try:\n",
    "                if metadata:\n",
    "                    all_text = metadata.get_text(strip=True)\n",
    "                    if all_text:\n",
    "                        text = all_text                \n",
    "                        # Extract date\n",
    "                        date_pattern = r'སྤེལ་དུས།\\s*(\\d{4}-\\d{2}-\\d{2})'\n",
    "                        date_match = re.search(date_pattern, text)\n",
    "                        if date_match:\n",
    "                            final_response['data']['meta_data'][\"Date\"] = date_match.group(1)\n",
    "                            \n",
    "                        # Extract source\n",
    "                        source_pattern = r'ཡོང་ཁུངས།\\s*(.+?)\\s*(?:\\||$)'\n",
    "                        source_match = re.search(source_pattern, text)\n",
    "                        Source = \"\"\n",
    "                        if source_match:\n",
    "                            Source = source_match.group(1).strip()\n",
    "                \n",
    "                        # Extract author\n",
    "                        author_pattern = r'རྩོམ་པ་པོ།\\s*(.+?)\\s*(?:\\||$)'\n",
    "                        author_match = re.search(author_pattern, text)\n",
    "                        Author = \"\"\n",
    "                        if author_match:\n",
    "                            Author = author_match.group(1).strip()\n",
    "                        full_Author_source = Author + \" ཡོང་ཁུངས།: \" + Source\n",
    "                        final_response['data']['meta_data'][\"Author\"] = full_Author_source\n",
    "                        \n",
    "            except AttributeError:\n",
    "                final_response['data']['meta_data'][\"Author\"] = \"Error fetching author\"\n",
    "                final_response['data']['meta_data'][\"Date\"] = \"Error fetching date\"\n",
    "            \n",
    "        # Extract body content\n",
    "        try:\n",
    "            body = full_body.find(\"div\", class_=\"sj4_left_list_abstract\")\n",
    "            if body:\n",
    "                paragraphs = body.find_all(\"p\")\n",
    "                if paragraphs:\n",
    "                    final_response['data']['body'][\"Text\"] = [para.get_text(strip=True) for para in paragraphs]\n",
    "                else:\n",
    "                    final_response['data']['body'][\"Text\"] = [\"\"]\n",
    "        except AttributeError as e:\n",
    "            final_response['data']['body'][\"Text\"] = [f\"Error fetching body content: {str(e)}\"]\n",
    "        \n",
    "        return final_response\n",
    "    except requests.Timeout:\n",
    "        final_response[\"Message\"] = \"Request timed out\"\n",
    "        final_response[\"Response\"] = 408  # Request Timeout\n",
    "        return final_response\n",
    "    except requests.RequestException as e:\n",
    "        final_response[\"Message\"] = f\"An error occurred while fetching the article: {str(e)}\"\n",
    "        final_response[\"Response\"] = getattr(e.response, 'status_code', 500)\n",
    "        return final_response\n",
    "    except Exception as e:\n",
    "        final_response[\"Message\"] = f\"An unexpected error occurred: {e}\"\n",
    "        final_response[\"Response\"] = 500\n",
    "        return final_response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21818ac-8d79-49c1-bf14-2c5866b811ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdfb3728-4a39-47e2-ab9a-79534a299fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'title': 'གནའ་དེང་ཟུང་འབྲེལ་གྱི་བར་སྐོར་ནས་སྔར་སོང་གི་ལོ་རྒྱུས་ལ་བསྐྱར་དྲན་བྱེད།',\n",
       "  'body': {'Audio': '',\n",
       "   'Text': ['གྲོང་ཁྱེར་རེ་རེར་རང་རང་གི་ཁྱད་ཆོས་ལྡན་པའི་ཁྲོམ་གཞུང་རྙིང་པ་རེ་ཡོད་ཅིང་། དེ་དག་གིས་གྲོང་ཁྱེར་གྱི་དྲན་ཤེས་མཚོན་ལ་ཡུལ་ལུང་དེ་གའི་གཏམ་རྒྱུད་ཀྱང་མཚོན། དཔེར་ན། པེ་ཅིང་གི་ཁྲང་ཨན་ཁྲོམ་གཞུང་དང་། ཧྲང་ཧའེ་ཡི་ནན་ཅིང་ལམ། ཁྲེང་ཏུའུ་ཡི་ཁྲུན་ཞི་ལམ་སོགས་ལྟ་བུ་ཡིན་ཏེ། ལྷ་སར་ཡང་ཁྲོམ་གཞུང་དེ་ལྟ་བུ་ཞིག་ཡོད་པ་ནི་བར་སྐོར་རེད།',\n",
       "    'ཡུལ་སྐོར་བས། བར་སྐོར་གྱི་བོད་ལུགས་བཟོ་བཀོད་ལ་ཁྱད་ཆོས་ཆེན་པོ་ལྡན།',\n",
       "    'ལྷ་སའི་བར་སྐོར་གྱི་རྩིག་པ་དཀར་པོ་དང་སྒེའུ་ཁུང་ནག་པོ་དག་ལས་བར་སྐོར་གྱི་ལོ་རྒྱུས་མཚོན་གྱི་ཡོད་ཅིང་། བོད་ལུགས་ཀྱི་ཤིང་བཟོས་སྒེའུ་ཁུང་ཁར་བཞག་པའི་མེ་ཏོག་འཇོག་སྒྲོམ་བར་ནས་ཕར་བལྟས་ན། ཕྲུ་གུ་འགའ་ཞིག་རྩེད་འཇོར་རོལ་བ་མཐོང་ཐུབ། ལོ་ངོ་1300ལྷག་གི་ལོ་རྒྱུས་ཡོད་པའི་གནའ་བོའི་ཁྲོམ་གཞུང་དེར་ལྷ་སའི་གནའ་གྲོང་གི་སྲོལ་རྒྱུན་གྱི་ཉམས་འགྱུར་དང་འཚོ་སྡོད་བྱེད་སྟངས་ཅུང་ཆ་ཚང་བར་སོར་འཇོག་བྱས་ཡོད་ལ། 2009ལོར་དེ་ཉིད“ཀྲུང་གོའི་ལོ་རྒྱུས་རིག་གནས་ཀྱི་ཁྲོམ་གཞུང་གྲགས་ཅན”ཁག་དང་པོའི་ནང་བདམས་པ་དང་། 2023ལོར་རྒྱལ་ཁབ་རིམ་པའི་ཡུལ་སྐོར་སྤྲོ་གསེང་ཁྲོམ་གཞུང་ཁག་གསུམ་པའི་ནང་བདམས་པ་རེད།',\n",
       "    'བར་སྐོར་ལྟེ་བར་བྱས་པའི་ཉེ་འཁོར་དུ་གནའ་བོའི་སྒོ་ར་ཅན་གྱི་ཁྲོམ་གཞུང་མང་པོ་ཡོད་ལ། དེ་དག་གིས་གྲོང་ཁུལ་རྙིང་པར་གསོན་ཤུགས་སྦྱིན་ཡོད། ཡུལ་སྐོར་བའི་ངོས་ནས་བརྗོད་ན། བར་སྐོར་ནི་ཡུལ་སྐོར་གྱི་མཛེས་ལྗོངས་ཤིག་ཡིན་ལ། ཡུལ་མིར་མཚོན་ན། བར་སྐོར་ནི་མི་རབས་ནས་མི་རབས་བར་བརྒྱུད་པའི་ལྷ་ས་བའི་དྲན་ཤེས་འདུས་པའི་ཁྱིམ་གཞིས་ཤིག་རེད།',\n",
       "    'ཇ་བསྲུབས་མ་ཕོར་པ་གང་འཐུང་བཞིན་ཐོག་བརྩེགས་ཁང་པའི་གཤམ་དུ་ཕར་འགྲོ་ཚུར་འོང་བྱེད་པའི་ཡུལ་སྐོར་བར་ལྟ་བའམ་ཡང་ན་བར་སྐོར་གྱི་རྐུབ་སྟེགས་རིང་པོའི་ཐོག་བསྡད་ནས་ཡུལ་སྐོར་བར་ཁ་བརྡ་གློད་པ་ནི། འདི་ལོ་ལོ་68ལ་སླེབས་པའི་ངག་དབང་ཚེ་རིང་གི་ཉིན་རེའི་འཚོ་བ་སྐྱེལ་སྟངས་རེད། “ཡུལ་སྐོར་བ་ཚོས་བོད་ལུགས་ཀྱི་ཁང་པར་ཁྱད་ཆོས་ཆེན་པོ་ལྡན་ཞེས་ཤོད་ཀྱི་འདུག གནའ་བོའི་སྒོ་ར་ཆེན་པོར་སྲུང་སྐྱོང་ཡག་པོ་དང་གསར་སྤེལ་ཡག་པོ་བྱས་ཚེ། གཞི་ནས་ཚང་མའི་སེམས་ཁོངས་སུ་ཡོད་པའི་ཕ་ཡུལ་སྐོར་གྱི་བག་ཆགས་གཏན་དུ་གནས་ཐུབ་ལ། ཡུལ་སྐོར་བར་ཉམས་ལེན་ཕུན་སུམ་ཚོགས་པོ་ཡང་སྦྱིན་ཐུབ”ཅེས་ངག་དབང་ཚེ་རིང་གིས་བཤད།',\n",
       "    'ལྷ་སའི་གནའ་གྲོང་གི་གྲུབ་ཆ་གལ་ཆེན་ཞིག་ཡིན་པའི་ངོས་ནས། 2012ལོར་ལྷ་ས་གྲོང་ཁྱེར་རིག་དངོས་སྡེ་ཚན་གྱིས་བར་སྐོར་ནང་གི་གནའ་བོའི་སྒོ་ར་ཆེན་པོར་ཁྱོན་ཡོངས་ནས་ཡོངས་བཤེར་དང་ཐོ་འགོད་ཀྱི་ལས་དོན་བསྒྲུབས་ནས། མཐར་གནའ་བོའི་སྒོ་ར་ཆེན་པོ་56ལྷ་ས་གྲོང་ཁྱེར་རིམ་པའི་རིག་དངོས་སྲུང་སྐྱོང་ཚན་པའི་གྲས་སུ་བཅུག་པ་དང་། དུས་མཚུངས་སུ་དེའི་གྲས་ཀྱི་ལོ་མང་རིང་ཉམས་གསོ་མ་ཐུབ་པའི་གནའ་བོའི་སྒོ་རར་སྲུང་སྐྱོང་རང་བཞིན་གྱི་ཉམས་གསོ་དང་རྒྱུན་གཏན་གྱི་བདག་སྐྱོང་ལས་དོན་གང་ལེགས་སྤེལ་བ་རེད།',\n",
       "    'ཡུལ་མིས།གནའ་བོའི་སྒོ་ར་ཆེན་པོ་ནས་དུས་རབས་ཀྱི་ཉམས་བཟང་རྒྱུན་ཆད་མེད་པར་མངོན།',\n",
       "    '“ང་ཚོ་ཁྲོམ་གཟིགས་སྒང་སྡེ་ཁུལ་དུ་སྒོ་ར་ཆེན་པོ་ཁྱོན་28ཡོད་པའི་ནང་། གནའ་བོའི་སྒོ་ར་ཆེན་པོ་3ནི་བདེ་ཆེན་རབ་བརྟན་ནུབ་དང་། ནམ་མཁའ་ནུབ། དར་པོ་གླིང་བཅས་ཡིན། དེ་དག་རེ་རེར་གཏམ་རྒྱུད་རེ་ཡོད་ལ་མིང་འདོགས་སྟངས་ལའང་དོན་སྙིང་ཆེན་པོ་འདུག”ཅེས་ཉེ་འགྲམ་གྱི་གནའ་བོའི་སྒོ་ར་ཆེན་པོའི་སྐོར་གླེང་སྐབས་སྐར་གསལ་གྱིས་ལྷུག་པོར་བརྗོད་པ་རེད།',\n",
       "    '1998ལོར་སྐར་གསལ་ནང་མི་ཡོངས་བར་སྐོར་ཁྲོམ་གཟིགས་སྒང་སྡེ་ཁུལ་གྱི་ཞྭ་སྒབ་པ་སྒོ་རའི་ནང་སྤོས་ཤིང་། སྐབས་དེར་སྒོ་རའི་ནང་དུད་ཚང་24དང་མི་80ལྷག་ཙམ་སྡོད་ཀྱི་ཡོད་པའི་ནང་བོད་རིགས་དང་། རྒྱ་རིགས། ཧུད་རིགས་སོགས་ཡོད། དུས་ཡུན་རིང་པོའི་ནང་ཁྱིམ་མཚེས་འཆམ་མཐུན་དང་ཕན་ཚུན་རོགས་རམ་བྱེད་པའི་དབང་གིས་ཚང་མ་སྒོ་ར་ཆེན་པོ་དེར་བརྩེ་དུང་ཟབ་མོ་ཡོད། འབྲེལ་ཡོད་སྡེ་ཚན་གྱིས་གནའ་བོའི་སྒོ་ར་ཆེན་པོར་སྲུང་སྐྱོང་བྱེད་ཤུགས་ཆེ་རུ་བཏང་བ་དང་བསྟུན་སྒོ་ར་ཆེན་པོའི་ཚོགས་ཆུང་གི་ཙུའུ་ཀྲང་དང་། སྒྲོག་འགྲེལ་པ། ཁྲེང་ཀོན་ཆུས་མི་དམངས་འཐུས་ཚོགས་ཀྱི་འཐུས་མི་བཅས་ཡིན་པའི་སྐར་གསལ་གྱིས་ཉིན་ལྟར་གནའ་གྲོང་གི་སྲང་ལམ་ཆུང་ངུའི་བར་དུ་ཕར་འགྲོ་ཚུར་འོང་བྱས་པས། གནའ་བོའི་ཁང་པར་སྔར་བས་རྒྱུས་མངའ་ཆེ་རུ་སོང་བ་དང་། ཁོངས་གཏོགས་ཁུལ་གྱི་སྒོ་ར་ཆེན་པོའི་འཕེལ་རྒྱས་དང་འགྱུར་ལྡོག་ལའང་དཔང་པོ་བྱས།',\n",
       "    'གྲོང་ཁུལ་རྙིང་པའི་ཡུལ་མིའི་ཐོན་སྐྱེད་དང་འཚོ་བའི་ཆ་རྐྱེན་སྔར་བས་ལེགས་སུ་གཏོང་བ་དང་ལོ་རྒྱུས་རིག་གནས་ཤུལ་བཞག་ལ་སྲུང་སྐྱོང་སྔར་བས་ཡག་པོ་བྱ་ཆེད། 2012ལོའི་ཟླ་12ཚེས་20ཉིན་ལྷ་ས་གྲོང་ཁྱེར་གྱིས་གྲོང་ཁུལ་རྙིང་པའི་སྲུང་སྐྱོང་ལས་གྲྭ་དངོས་སུ་འགོ་ཚུགས་ཤིང་། ལས་གྲྭའི་ཞིབ་ཕྲའི་ནང་དོན་ཐད་ཆུ་འབུད་སྒྱུར་བཀོད་དང་། གློག་སྐུད་སྒྱུར་བཀོད། གྲོང་ཁུལ་རྙིང་པའི་དྲོད་འདོན་ལས་གྲྭ། གནའ་གྲོང་གི་ཁྱད་ལྡན་ཉམས་འགྱུར་སྲུང་སྐྱོང་ལས་གྲྭ་སོགས་ཚུད་ཡོད་པ་རེད།',\n",
       "    '“སྔོན་ཆད་ཀྱི་སྒོ་ར་ཆེན་པོའི་ཆུ་གློག་སོགས་རྨང་གཞིའི་སྒྲིག་བཀོད་འཐུས་ཚང་མེད་པ་དང་རྩིག་པ་ཁག་གཅིག་གས་ཡོད་ལ། མཚན་མོར་སྲང་ལམ་ཡོངས་ནག་རོག་རོག་ཡིན་པ་སོགས་མདོར་ན་ཁོར་ཡུག་སྤྱིའི་ཆ་ནས་ཞན་པོ་ཡོད”ཉམས་གསོ་སྲུང་སྐྱོང་དང་བཅོས་སྒྲིག་བྱས་པ་བརྒྱུད་གནའ་བོའི་སྒོ་ར་བཙོག་ཟིང་ཞན་གསུམ་ནས་གཙང་སྦྲ་དོད་པོར་གྱུར་ཏེ་ཡུལ་མིའི་འཚོ་བའི་སྤུས་ཚད་ཀྱང་རིམ་བཞིན་ལེགས་སུ་སོང་ཡོད་ཅེས་སྐར་གསལ་གྱིས་ཕྱིར་དྲན་བྱེད་བཞིན་དུ་བརྗོད།',\n",
       "    '“2019ལོ་ནས་བཟུང་། ཁྲོམ་གཟིགས་སྒང་སྡེ་ཁུལ་གྲོང་མི་ཨུ་ལྷན་གྱིས་སྒོ་ར་ཆེན་པོའི་གང་སར་ཉམས་གསོ་ཐེངས་མང་བྱས་པར་བརྟེན། ད་ཆ་ཐོག་བརྩེགས་ཁང་པའི་བར་གྱི་ལམ་ག་གཙང་བ་མ་ཟད་གད་སྙིགས་སྤུངས་པའང་མཐོང་རྒྱུ་མེད། ས་འོག་ཆུ་ལམ་ཡང་འགག་གི་མེད་ལ་ལམ་སྒྲོན་དང་ས་འོག་ཆུ་ལམ་གྱི་ཁ་གཅོད་ལ་ད་དུང་ང་ཚོའི‘བར་སྐོར་གྱི་ཁྱད་ཆོས’ཡོད”ཅེས་སྐར་གསལ་གྱིས་བཤད།',\n",
       "    'བར་སྐོར་གནའ་གྲོང་དོ་དམ་ཨུ་ལྷན་གྱིས།ལོ་རྒྱུས་དང་རིག་གནས་ཀྱི་རྩ་བ་རྒྱུན་འཛིན་བྱེད་དགོས།',\n",
       "    '“རིག་དངོས་ཀྱི་སྔར་ཡོད་རིན་ཐང་ལ་ཐེ་གཏོགས་དང་གཏོར་བཤིག་གཏོང་བའི་ཉེན་ཁ་སྔོན་འགོག་བྱ་ཆེད། གནའ་བོའི་སྒོ་ར་ཆེན་པོ་ཉམས་གསོ་བྱེད་རིང་ང་ཚོ་དོ་དམ་ཨུ་ལྷན་གྱིས་འབྲེལ་ཡོད་ཁྲིམས་སྲོལ་གཞིར་བཟུང་ཞིབ་མཆན་འགོད་པའི་གོ་རིམ་ནན་པོ་བཟོས་ཏེ། གནའ་བོའི་སྒོ་ར་ཆེན་པོའི་ཉམས་གསོའི་ལས་དོན་དེ་ཆེད་ལས་ཀྱི་མཛུབ་ཁྲིད་དང་ལྟ་སྐུལ་དོ་དམ་འོག་སྤེལ་ཐུབ་པར་བྱེད་ཀྱི་ཡོད། གོ་རིམ་དེ་རིགས་ཀྱིས་རིག་དངོས་ཀྱི་དངོས་ཡོད་རང་བཞིན་དང་ཆ་ཚང་རང་བཞིན་ལ་འགན་ལེན་བྱས་པ་མ་ཟད། མི་རབས་རྗེས་མར་རིག་གནས་ཀྱི་རྒྱུ་ནོར་རྩ་ཆེན་ཡང་བཞག་ཡོད”ཅེས་བར་སྐོར་གནའ་གྲོང་དོ་དམ་ཨུ་ལྷན་གྱི་འབྲེལ་ཡོད་འགན་འཁུར་བས་བཤད།',\n",
       "    'ཉེ་བའི་ལོ་ཤས་རིང་། བར་སྐོར་གནའ་གྲོང་དོ་དམ་ཨུ་ལྷན་གྱིས“སྲུང་སྐྱོང་གཙོ་བོར་བྱེད་པ་དང་། སྔར་ཡོད་ཇི་བཞིན་ཉམས་གསོ། གནའ་ཉམས་སོར་འཇོག”བཅས་ཀྱི་རྩ་དོན་གཞིར་བཟུང་གནའ་བོའི་ཁང་པར་ཉམས་གསོ་བྱས་པ་དང་འབྲེལ། ཡུལ་སྐོར་ཐོན་ཁུངས་ལ་གཞི་ཚུགས་ཏེ་རིག་གནས་དང་ཡུལ་སྐོར་མཉམ་འདྲེས་ཀྱི་ཐོག་ནས་བར་སྐོར་གྱི་གནའ་བོའི་སྒོ་ར་ཆེན་པོའི་ལོ་རྒྱུས་ཀྱི་རྣམ་པ་དང་། རིག་གནས་ཀྱི་ནང་དོན། དམིགས་བསལ་གྱི་ཡིད་དབང་འཕྲོག་ཤུགས་བཅས་དྲིལ་བསྒྲགས་དང་འགྲེམས་སྟོན་བྱས་ཏེ་གནའ་བོའི་བཟོ་བཀོད་ལ་སྐྱེ་སྟོབས་གསར་པ་འཕེལ་བར་བྱས་ཡོད།',\n",
       "    'བར་སྐོར་གྱི་གནའ་བོའི་སྒོ་ར་ཆེན་པོ་ཞིག་ཏུ། 95ནང་སྐྱེས་ཀྱི་བོད་རིགས་གཞོན་པ་བསྟན་དར་གྱིས་མིང་ལ“གཟིམ་ཤག”ཅེས་པའི་ཀོག་ཧྥེ་འཐུང་ས་ཞིག་བཙུགས་ཡོད། དེ་གར་ཀོག་ཧྥེ་འཐུང་གིན་དཔེ་དེབ་ལྟ་བ་དང་། ཀོག་ཧྥེ་ཡི་དྲི་ཞིམ་རབ་ཏུ་འཐུལ་ནས་གནའ་བོའི་སྒོ་རར་གསོན་ཤུགས་གསར་པ་སྦྱིན་ཡོད། “ཀོག་ཧྥེ་འཐུང་སའི་ཚོང་ཧ་ཅང་ཡག་པོ་འདུག ངས་རྟག་ཏུ་མགྲོན་པོ་ཚོར་སྒོ་ར་ཆེན་པོའི་གཏམ་རྒྱུད་ཤོད་ཀྱི་ཡོད། ང་ཆུང་དུས་ནས་འདི་གར་འཚར་ལོངས་བྱུང་བ་དང་སྒོ་ར་ཆེན་པོའི་འགྱུར་ལྡོག་དངོས་སུ་བརྒྱུད་མྱོང”ཞེས་བསྟན་དར་གྱིས་བཤད། གནའ་བོའི་སྒོ་རས་མི་རབས་ནས་མི་རབས་བར་གྱི་གཏམ་རྒྱུད་ལ་དཔང་པོ་བྱས་ཤིང་། སྒོ་ར་དེ་སྔོན་ཆད་ཧ་གོ་མཁན་ཉུང་ཉུང་ཡིན་པ་དང་ད་ཆ་ཀོག་ཧྥེ་འཐུང་ས་གཉེར་བ་ལས་གནའ་བོའི་སྒོ་རས་ཕྱོགས་བཞི་མཚམས་བརྒྱད་ནས་ཡོང་བའི་མགྲོན་པོ་བསུ་བཞིན་ཡོད།',\n",
       "    'ད་ཆ་གནའ་བོའི་སྒོ་ར་ཆེན་པོར་ལྡན་པའི་ཐུན་མོང་མ་ཡིན་པའི་ལོ་རྒྱུས་ཀྱི་རྗེས་ཤུལ་དང་གདོད་མའི་རྣམ་པ་དེ་དམངས་སྲོལ་གནས་ཚང་དང་། ཀོག་ཧྥེ་འཐུང་ས། རིག་གནས་བསམ་བཀོད་ཚོང་ཁང་སོགས་དེང་རབས་ཀྱི་གཞི་རྒྱུ་དང་གཞི་གཅིག་ཏུ་འདྲེས་ནས། ལྷ་སའི་ཡུལ་སྐོར་རིག་གནས་ཀྱི་མིང་བྱང་གསར་པ་དང་ས་གནས་དེ་གའི་ཡུལ་མིའི་བདེ་སྐྱིད་འཚོ་བ་མངོན་པའི་སྐར་ཁུང་ཞིག་ཏུ་གྱུར།',\n",
       "    'འགན་འཁུར་རྩོམ་སྒྲིག་པ།\\u3000ཚེ་བརྟན་རྡོ་རྗེ།']},\n",
       "  'meta_data': {'URL': 'https://tb.xzxw.com/xw/2024-06/19/content_6198357.html#',\n",
       "   'Author': 'ཚེ་སྐྱིད། དབྱངས་ཅན་སྒྲོལ་མ། ཡོང་ཁུངས།: ཀྲུང་གོའི་བོད་ཀྱི་གསར་འགྱུར་དྲ་བ།',\n",
       "   'Date': '2024-06-19',\n",
       "   'Tags': ['དབུ་ཤོག', 'གསར་འགྱུར།', 'སྐབས་དོན་ཆབ་སྲིད།']}},\n",
       " 'Message': 'Success',\n",
       " 'Response': 200}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://tb.xzxw.com/xw/2024-06/19/content_6198357.html#\"\n",
    "# url = \"https://tb.xzxw.com/wxys/2024-07/15/content_6227621.html\"\n",
    "scrape_tb_xzxw_article_content(url, tags=\"དཔྱད་གཏམ།\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe349a6-67ab-49f1-bcba-871bfcb0d8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c1dfd-23c4-4748-b2b9-6f32437c4d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01d677-0fb7-401e-a10f-ce930692af97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d4c08-b853-4134-9b0d-58ac6b65de53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df567d41-0137-470a-b685-9fc91b732da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cd2be89-8b09-4730-b36f-8e49af332c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 results:\n",
      "Source: ཀྲུང་གོའི་བོད་ཀྱི་གསར་འགྱུར་དྲ་བ།\n",
      "Author: ཚེ་སྐྱིད། དབྱངས་ཅན་སྒྲོལ་མ།\n",
      "Date: 2024-06-19\n",
      "\n",
      "Test 2 results:\n",
      "Source: ཀྲུང་གོའི་བོད་ཀྱི་གསར་འགྱུར་དྲ་བ།\n",
      "Author: \n",
      "Date: 2024-07-15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_metadata(text):\n",
    "    metadata = {\n",
    "        \"Source\": \"\",\n",
    "        \"Author\": \"\",\n",
    "        \"Date\": \"\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Extract source\n",
    "        source_pattern = r'ཡོང་ཁུངས།\\s*(.+?)\\s*(?:\\||$)'\n",
    "        source_match = re.search(source_pattern, text)\n",
    "        if source_match:\n",
    "            metadata[\"Source\"] = source_match.group(1).strip()\n",
    "\n",
    "        # Extract date\n",
    "        date_pattern = r'སྤེལ་དུས།\\s*(\\d{4}-\\d{2}-\\d{2})'\n",
    "        date_match = re.search(date_pattern, text)\n",
    "        if date_match:\n",
    "            metadata[\"Date\"] = date_match.group(1)\n",
    "\n",
    "        # Extract author\n",
    "        author_pattern = r'རྩོམ་པ་པོ།\\s*(.+?)\\s*(?:\\||$)'\n",
    "        author_match = re.search(author_pattern, text)\n",
    "        if author_match:\n",
    "            metadata[\"Author\"] = author_match.group(1).strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        metadata[\"Source\"] = \"Error fetching source\"\n",
    "        metadata[\"Author\"] = \"Error fetching author\"\n",
    "        metadata[\"Date\"] = \"Error fetching date\"\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Test cases\n",
    "test1 = \"ཡོང་ཁུངས།  ཀྲུང་གོའི་བོད་ཀྱི་གསར་འགྱུར་དྲ་བ།   |     རྩོམ་པ་པོ།  ཚེ་སྐྱིད། དབྱངས་ཅན་སྒྲོལ་མ།   |     སྤེལ་དུས།  2024-06-19\"\n",
    "test2 = \"ཡོང་ཁུངས།  ཀྲུང་གོའི་བོད་ཀྱི་གསར་འགྱུར་དྲ་བ།   |     སྤེལ་དུས།  2024-07-15\"\n",
    "\n",
    "# Process test cases\n",
    "for i, test in enumerate([test1, test2], 1):\n",
    "    result = extract_metadata(test)\n",
    "    print(f\"Test {i} results:\")\n",
    "    for key, value in result.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cacbb9-e805-4537-8414-dfa2c79c3df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
