{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2258a036-edcc-4203-a032-7fd4c75a16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076b685-d470-4ebb-98fe-89e831e0fa06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0893f489-550d-40d7-9ae8-c5a76a07eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54688e52-c01e-4889-946c-c3098c2ab22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_xizang_news_page_article_links(url, base_url):\n",
    "    \"\"\"\n",
    "    Extracts all article links from a given xizang_news webpage.\n",
    "\n",
    "    This function scrapes the provided URL and extracts links to individual articles\n",
    "    found on the page.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL of the xizang_news webpage containing article links.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "            \"Links\": List[],\n",
    "            \"Message\": string,\n",
    "            \"Response\": int,\n",
    "            \"source_url\": string\n",
    "        }\n",
    "    Raises:\n",
    "    requests.RequestException: If there's an error fetching the webpage.\n",
    "    ValueError: If the expected HTML structure is not found on the page.\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    final_response = {\n",
    "        \"Links\": [],\n",
    "        \"Message\": \"Success\",\n",
    "        \"Response\": 200,\n",
    "        \"source_url\": url\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = requests.get(url, headers=headers, timeout=(5, 60-5))\n",
    "        response.raise_for_status()\n",
    "        end_time = time.time()\n",
    "\n",
    "        if end_time-start_time > 50:\n",
    "            print(f\"This ULR Took more then 50s: {url}\")\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # # Getting all the links of articles \n",
    "        all_links = []\n",
    "        article_block = soup.find_all(\"div\", id=\"lcqwJbzJW\")\n",
    "        if article_block:\n",
    "            for each_head in article_block:\n",
    "                article_links = each_head.find_all(\"a\")\n",
    "                if article_links:\n",
    "                    for each_link in article_links:\n",
    "                        full_url = urljoin(base_url, each_link.get(\"href\"))\n",
    "                        all_links.append(full_url)\n",
    "                        \n",
    "        final_response[\"Links\"] = all_links\n",
    "        return final_response\n",
    "     \n",
    "    except requests.Timeout:\n",
    "        final_response[\"Message\"] = \"Request timed out\"\n",
    "        final_response[\"Response\"] = 408  # Request Timeout\n",
    "        return final_response\n",
    "    except requests.RequestException as e:\n",
    "        # print(f\"An error occurred while fetching the webpage: {e}\")\n",
    "        final_response[\"Message\"] = f\"An error occurred while fetching the webpage: {e}\"\n",
    "        final_response[\"Response\"] = getattr(e.response, 'status_code', None)\n",
    "        return final_response\n",
    "    except ValueError as e:\n",
    "        # print(f\"An error occurred while parsing the webpage: {e}\")\n",
    "        final_response[\"Message\"] = f\"An error occurred while parsing the webpage: {e}\"\n",
    "        final_response[\"Response\"] = 404\n",
    "        # getattr(e.response, 'status_code', None)\n",
    "        return final_response\n",
    "    except Exception as e:\n",
    "        # print(f\"An unexpected error occurred: {e}\")\n",
    "        final_response[\"Message\"] = f\"An unexpected error occurred: {e}\"\n",
    "        final_response[\"Response\"] = 500\n",
    "        return final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bb97c0-397e-413e-91b6-0d168800449c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed414892-9c45-4db7-a9ae-e56ac4b3775e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c598f0ac-0079-4ccf-a24e-e552628cd629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Links': ['http://www.tbmgar.com/zwndbw.asp?id=5020&Zhg=001&lcqwid=282&lcqbID=70&NdRak_ID=ZamqowLc#ndbwNdCam',\n",
       "  'http://www.tbmgar.com/zwndbw.asp?id=4534&Zhg=001&lcqwid=282&lcqbID=70&NdRak_ID=ZamqowLc#ndbwNdCam',\n",
       "  'http://www.tbmgar.com/zwndbw.asp?id=4516&Zhg=001&lcqwid=282&lcqbID=70&NdRak_ID=ZamqowLc#ndbwNdCam',\n",
       "  'http://www.tbmgar.com/zwndbw.asp?id=4490&Zhg=001&lcqwid=282&lcqbID=70&NdRak_ID=ZamqowLc#ndbwNdCam',\n",
       "  'http://www.tbmgar.com/zwndbw.asp?id=4482&Zhg=001&lcqwid=282&lcqbID=70&NdRak_ID=ZamqowLc#ndbwNdCam',\n",
       "  'http://www.tbmgar.com/zwndbw.asp?id=4462&Zhg=001&lcqwid=282&lcqbID=70&NdRak_ID=ZamqowLc#ndbwNdCam',\n",
       "  'http://www.tbmgar.com/zwndbw.asp?id=4443&Zhg=001&lcqwid=282&lcqbID=70&NdRak_ID=ZamqowLc#ndbwNdCam',\n",
       "  'http://www.tbmgar.com/zwndbw.asp?id=4438&Zhg=001&lcqwid=282&lcqbID=70&NdRak_ID=ZamqowLc#ndbwNdCam',\n",
       "  'http://www.tbmgar.com/zwndbw.asp?id=4406&Zhg=001&lcqwid=282&lcqbID=70&NdRak_ID=ZamqowLc#ndbwNdCam',\n",
       "  'http://www.tbmgar.com/zwndbw.asp?id=4377&Zhg=001&lcqwid=282&lcqbID=70&NdRak_ID=ZamqowLc#ndbwNdCam'],\n",
       " 'Message': 'Success',\n",
       " 'Response': 200,\n",
       " 'source_url': 'http://www.tbmgar.com/lcqwbw.asp?id=282#ndbwNdCam'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"http://www.tbmgar.com/\"\n",
    "url = \"http://www.tbmgar.com/lcqwbw.asp?id=282#ndbwNdCam\"\n",
    "extract_tbmgar_page_article_links(url, base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a22674e-af54-45c3-9667-75be1ce42357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0efae0e1-4c58-41bc-8643-fe002b6ca33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ti.zangdiyg.com/category/index/id/61\n"
     ]
    }
   ],
   "source": [
    "# custom_url = 'https://ti.zangdiyg.com/category/index/id/61.html'\n",
    "# print(custom_url.replace(\".html\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da43a3c-fa6d-4017-aaf8-718649005b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ff984-7034-4f42-aadb-0ced1eff2de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd008b9d-206b-4170-8f45-d6bcb77e2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_tbmgar_article_content(url, tags):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    final_response = {\n",
    "        \"data\": {\n",
    "            'title': \"\",\n",
    "            'body': {\"Audio\": \"\", \"Text\": []},\n",
    "            'meta_data': {'URL': url, 'Author': \"\", 'Date': \"\", 'Tags': [tags]}\n",
    "        },\n",
    "        \"Message\": \"Success\",\n",
    "        \"Response\": 200\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Make the request to the URL\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse the page content with BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        tags_body = soup.find(\"td\", class_=\"xczdNzd\")\n",
    "        tags = []\n",
    "        if tags_body:\n",
    "            tag_list = tags_body.find_all(\"a\")\n",
    "            if tag_list:\n",
    "                for tag in tag_list:\n",
    "                    each_tag = tag.get_text(strip=True)\n",
    "                    tags.append(each_tag)\n",
    "                final_tag = tags_body.find(\"font\")\n",
    "                if final_tag:\n",
    "                    tags.append(final_tag.get_text(strip=True))\n",
    "                final_response['data']['meta_data'][\"Tags\"] = tags\n",
    "        \n",
    "        full_body = soup.find('table', class_=\"ndbwTT\")\n",
    "        if full_body:\n",
    "            # Extract title\n",
    "            title = soup.find('font', class_='NdbwKx')\n",
    "            if title:\n",
    "                title_text = title.get_text(strip=True)\n",
    "            else:\n",
    "                title_text = \"\"\n",
    "            final_response['data'][\"title\"] = title_text\n",
    "            \n",
    "            metadata = full_body.find('table', class_=\"ND_zzbSYg\")\n",
    "            # Extracting Meta Data\n",
    "            try:\n",
    "                if metadata:\n",
    "                    each_meta = metadata.find_all(\"td\")\n",
    "                    if each_meta:\n",
    "                        # Extract author\n",
    "                        author = each_meta[0].get_text(strip=True)\n",
    "                        # Extract date\n",
    "                        date_text = each_meta[1].get_text(strip=True)\n",
    "                        date = re.search(r'\\d{4}/\\d{1,2}/\\d{1,2}', date_text)\n",
    "                        if date:\n",
    "                            final_response['data']['meta_data'][\"Date\"] = date.group()\n",
    "                        final_response['data']['meta_data'][\"Author\"] = author\n",
    "            except AttributeError:\n",
    "                final_response['data']['meta_data'][\"Author\"] = \"Error fetching author\"\n",
    "                final_response['data']['meta_data'][\"Date\"] = \"Error fetching date\"\n",
    "       # Extract body content\n",
    "        try:\n",
    "            body = full_body.find(\"table\", id=\"Nd_mni\")\n",
    "            if body:\n",
    "                # Extract all text content, including spans\n",
    "                all_text = body.find_all(string=True)\n",
    "                \n",
    "                # Filter out empty strings and strip whitespace\n",
    "                filtered_text = [text.strip() for text in all_text if text.strip()]\n",
    "                \n",
    "                # Remove duplicate consecutive lines (which often occur due to formatting)\n",
    "                final_text = []\n",
    "                for line in filtered_text:\n",
    "                    if not final_text or line != final_text[-1]:\n",
    "                        final_text.append(line)\n",
    "                \n",
    "                final_response['data']['body'][\"Text\"] = final_text\n",
    "            else:\n",
    "                final_response['data']['body'][\"Text\"] = [\"\"]\n",
    "        except AttributeError as e:\n",
    "            final_response['data']['body'][\"Text\"] = [f\"Error fetching body content: {str(e)}\"]\n",
    "        \n",
    "        return final_response\n",
    "    except requests.Timeout:\n",
    "        final_response[\"Message\"] = \"Request timed out\"\n",
    "        final_response[\"Response\"] = 408  # Request Timeout\n",
    "        return final_response\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        final_response[\"Message\"] = f\"An error occurred while fetching the article: {str(e)}\"\n",
    "        final_response[\"Response\"] = getattr(e.response, 'status_code', 500)\n",
    "        return final_response\n",
    "    except Exception as e:\n",
    "        # print(f\"An unexpected error occurred: {e}\")\n",
    "        final_response[\"Message\"] = f\"An unexpected error occurred: {e}\"\n",
    "        final_response[\"Response\"] = 500\n",
    "        return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21818ac-8d79-49c1-bf14-2c5866b811ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdfb3728-4a39-47e2-ab9a-79534a299fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': {'title': 'སི་ཏུ་རིན་པོ་ཆེས་སྡེ་དགེའི་བཀའ་འགྱུར་ཞུ་དག་མཛད་སྟངས།',\n",
       "  'body': {'Audio': '',\n",
       "   'Text': ['བོད་འདིར་སྔ་བའི་སྣར་ཐང་བཀའ་འགྱུར་དང་། །སི་ཏུ་དགེ་བློའི་ཚལ་པ་བཀའ་འགྱུར་དང་། །རྒྱལ་རྩེ་ཐེམས་སྤང་གྲགས་པའི་བཀའ་འགྱུར་རྒྱུན། །རྒྱ་ནག་ཏཱ་མིང་རྒྱལ་པོའི་བཀའ་འགྱུར་རྒྱུན། །འཇང་ཡུལ་རྒྱལ་པོས་བཞེངས་པའི་བཀའ་འགྱུར་པར། །དེང་སང་ལི་ཐང་བཞུགས་པ་འདི་ཉིད་དང་། །ཨ་གཉེན་པཀྵིའི་ཐུགས་དམ་བཀའ་འགྱུར་དང་། །རྒྱལ་དབང་ལྔ་པའི་དགོངས་བཀོད་ལྷོ་རྫོང་གི། །བཀའ་འགྱུར་བཅས་དང་འདུལ་མདོ་ཤེར་ཕྱིན་དང་། །གསང་སྔགས་རྒྱུད་འབུམ་བཅས་པ་སོ་སོ་ཡི། །དཔེ་ཁུངས་བཙུན་པ་རྣམས་དང་གོ་བསྡུར་ཞིང་། །ཁྱད་པར་སྙིགས་དུས་བསྟན་པའི་སྒྲོན་མེ་མཆོག །མཁས་པ་ཆེན་པོ་བུ་སྟོན་རིན་ཆེན་གྲུབ། །གང་གིས་དཀར་ཆག་བཏབ་པ་ཚད་མར་འཛིན། །གཞན་ཡང་བྲིས་པ་ལས་འཛིན་ལེ་ལོ་ཡིས། །ནོར་འཁྲུལ་སོར་ཆུད་ལོག་དཔྱོད་བསྒྱུར་ཉེས་རྣམས། །འཕགས་ཡུལ་རྒྱ་དཔེའི་སྟེང་ནས་བསྒྱུར་ཞིང་ཞུས། །གཏན་ལ་ཕབ་ཅིང་ཐེ་ཚོམ་བྱུང་བ་རྣམས། །རྒྱ་འགྲེལ་དང་བསྟུན་ཚད་མ་ཉིད་དུ་བཅོས། །སྔགས་བཏུ་ཡོད་པ་དེ་ཉིད་དག་དང་བསྟུན། །ལེགས་པར་ལེགས་སྦྱར་སཾ་སྐྲྀ་ཏ་ཡི་སྐད། །འགྲོ་ལྡིང་སྐད་དང་པི་ཤཱ་ཙི་ཡི་སྐད། །ཟུར་ཆག་ཨ་བ་བྷྲཾ་ཤའི་སྐད་དང་ནི། །གསང་བ་བརྡ་ཡི་སྐད་སོགས་སྒྲ་སྐད་རྣམས། །ཀུན་ལ་ཐོགས་མེད་མ་ཧཱ་པཎྜི་ཏ། །འཇམ་མགོན་ཟུར་ཕུད་ལྔ་པ་གཞན་དུ་གང་། །མཁས་པ་གཞན་རྣམས་ནེ་ཙོའི་ཀློག་ཙམ་ལགས། །དཔེར་ན་ནོར་བུ་ཀེ་ཏ་ཀ་ཞེས་པས། །ཆུ་རྣམས་རྙོགས་བྲལ་བགྲུང་ཞིང་དྭངས་པར་བྱེད། །དེ་བཞིན་ཆོས་ཀྱི་སྤྱན་ལྡན་སི་ཏུ་པས། །རྒྱལ་སྲུང་དམ་ཆོས་སྐྱོན་རྣམས་སྦྱོང་བར་མཛད། །དེ་ནས་བོད་ཀྱི་བརྡ་དག་སྡེབ་སྦྱོར་རྣམས། །འཇམ་དབྱངས་ཐུ་མིའི་སུམ་རྟགས་དགོངས་དོན་ཏེ། །འདི་ལ་མཁས་པ་འགའ་ཡིས་དཔྱད་པ་ཡི། །བརྡ་དག་བསྟན་བཅོས་སྣ་ཚོགས་བཞུགས་པ་ལས། །འདུལ་མདོ་རྒྱུད་གསུམ་བརྡ་དག་མཚུངས་པར་མཛད། །ཡུལ་སྐད་མ་མྱ་ས་སྩོགས་ད་དྲག་བསྡུས། །འགྱུར་ཆད་བསྐང་ཞིང་བསྒྱུར་ཉེས་དག་པར་ཕབ། །འདི་ནི་བསྲེག་བཅད་བརྡར་བའི་གསེར་བཞིན་གཙང་། །ལེགས་ཆ་ཀུན་རྫོགས་ཉ་རྒྱས་ཟླ་བ་འདྲ། །གོང་འོག་སྡེབ་ལེགས་རི་རབ་ལྷུན་པོ་འདྲ། །དགོས་འདོད་ཀུན་འབྱུང་དཔག་བསམ་ལྗོན་ཤིང་བཞིན། །དེ་ཕྱིར་བོད་དང་བོད་ཆེན་མཁས་གྲུབ་ཚོགས། །ཐུགས་དགོངས་མཉམ་པས་མགྲིན་གཅིག་སྨྲ་བ་ལྟར། །སྡེ་དགེ་ཆོས་རྒྱལ་བཀའ་འགྱུར་རིན་པོ་ཆེ། །སྔོན་གྱི་ཆོས་སྦྱིན་ཀུན་གྱིས་འགྲན་ཟླ་མེད། །ཅེས་པའི་གྲགས་པས་ས་སྟེང་ཀུན་ལ་ཁྱབ། །',\n",
       "    'ཅེས་རབ་བྱུང་བཅུ་གསུམ་པའི་ལྕགས་ཕག་སྤྱི་ལོ༡༧༩༡ལོར་སྡེ་དགེའི་ཆོས་རྒྱལ་ཆེན་པོའི་དྲུང་འཚོ་བ་གུ་རུ་འཕེལ་གྱིས་བྲིས་པའི་སྡེ་དགེའི་རྒྱལ་རབས་ཁམས་གསུམ་ཟིལ་གནོན་འབྲེལ་ཚད་དོན་ལྡན་ལས་སི་ཏུ་པཎ་ཆེན་གྱིས་བཀའ་འགྱུར་ཞུ་དག་མཛད་སྟངས་སྐོར་ཁོལ་དུ་ཕྱུང་བའོ། །']},\n",
       "  'meta_data': {'URL': 'http://www.tbmgar.com/zwndbw.asp?id=5026&NdRak_ID=ZamqowLc#ndbwNdCam',\n",
       "   'Author': 'རྩོམ་སྒྲིག་པ།\\xa0\\xa0དོ་དམ་པ།',\n",
       "   'Date': '2023/12/26',\n",
       "   'Tags': ['གཙོ་ངོས།',\n",
       "    'རྩོམ་རིག',\n",
       "    'སྙན་རྩོམ།',\n",
       "    'སི་ཏུ་རིན་པོ་ཆེས་སྡེ་དགེའི་བཀའ་འགྱུར་ཞུ་དག་མཛད་སྟངས།']}},\n",
       " 'Message': 'Success',\n",
       " 'Response': 200}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.tbmgar.com/zwndbw.asp?id=5026&NdRak_ID=ZamqowLc#ndbwNdCam\"\n",
    "# url = \"http://www.tbmgar.com/zwndbw.asp?id=4886&NdRak_ID=ZamqowLc#ndbwNdCam\"\n",
    "scrape_tbmgar_article_content(url, tags=\"དཔྱད་གཏམ།\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe349a6-67ab-49f1-bcba-871bfcb0d8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c1dfd-23c4-4748-b2b9-6f32437c4d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01d677-0fb7-401e-a10f-ce930692af97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6bffb0-13d2-4b11-952f-4122c7e2699b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
