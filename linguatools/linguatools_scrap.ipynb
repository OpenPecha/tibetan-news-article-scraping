{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Dict, Any, List\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read each page of linguatools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_extract(element, default=''):\n",
    "    return element.text.strip() if element else default\n",
    "\n",
    "def scrape_linguatools_translation(url: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Scrapes an article from the Tibetan English Czech (linguatools) website.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL of the linguatools to scrape.\n",
    "\n",
    "    Returns:\n",
    "    Dict[str, Any]: A dictionary containing the scraped information and status details.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    each_data_empty = {\n",
    "        \"English\": {\n",
    "                'Word': \"\",\n",
    "                'POS': \"\",\n",
    "                'Sentence': \"\"\n",
    "            },\n",
    "            \"Tibetan\": {\n",
    "                'Word': \"\",\n",
    "                'phonetic': \"\",\n",
    "                'Sentence': \"\"\n",
    "            },\n",
    "            \"czech\": {\n",
    "                'Word': \"\",\n",
    "                'Sentence': \"\"\n",
    "            },\n",
    "            \"meta_data\": {\n",
    "                \"Comment\": \"\",\n",
    "                \"Source\": \"\"\n",
    "            },\n",
    "            \"Message\": \"\"\n",
    "    }\n",
    "    \n",
    "    final_response = {\n",
    "        \"data\": \"\",\n",
    "        \"Message\": \"Success\",\n",
    "        \"Response\": 200\n",
    "    }\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=120)\n",
    "        response.raise_for_status()\n",
    "        All_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract body\n",
    "        Table_body = All_soup.find('tbody', id='entries')\n",
    "        if Table_body:\n",
    "            all_table_rows = Table_body.find_all(\"tr\")\n",
    "            try:\n",
    "                All_data = {}\n",
    "                index = 0\n",
    "                for soup in all_table_rows:\n",
    "                    try:\n",
    "                        each_data = {\n",
    "                            \"English\": {\n",
    "                                'Word': safe_extract(soup.find('b')),\n",
    "                                'POS': safe_extract(soup.find('span', class_='text-muted').find('small') if soup.find('span', class_='text-muted') else None),\n",
    "                                'Sentence': safe_extract(soup.find_all('small')[1] if len(soup.find_all('small')) > 1 else None)\n",
    "                            },\n",
    "                            \"Tibetan\": {\n",
    "                                'Word': safe_extract(soup.find('span', style='font-size:120%;').find('b') if soup.find('span', style='font-size:120%;') else None),\n",
    "                                'phonetic': safe_extract(soup.find_all('span', class_='text-muted')[1].find('small') if len(soup.find_all('span', class_='text-muted')) > 1 else None).strip('[]'),\n",
    "                                'Sentence': safe_extract(soup.find_all('span', style='font-size:120%;')[1] if len(soup.find_all('span', style='font-size:120%;')) > 1 else None)\n",
    "                            },\n",
    "                            \"czech\": {\n",
    "                                'Word': safe_extract(soup.find_all('td')[2].find('b') if len(soup.find_all('td')) > 2 else None),\n",
    "                                'Sentence': safe_extract(soup.find_all('td')[2].find('small') if len(soup.find_all('td')) > 2 else None)\n",
    "                            },\n",
    "                            \"meta_data\": {\n",
    "                                \"Comment\": safe_extract(soup.find_all('td')[3] if len(soup.find_all('td')) > 3 else None),\n",
    "                                \"Source\": safe_extract(soup.find_all('span', class_='text-muted')[-1] if soup.find_all('span', class_='text-muted') else None)\n",
    "                            },\n",
    "                            \"Message\": \"Success\", \n",
    "                        }\n",
    "                        All_data[index] = each_data\n",
    "                        index += 1\n",
    "                    except Exception as e:\n",
    "                        each_data_empty['Message'] = str(e)\n",
    "                        All_data[index] = each_data_empty\n",
    "                        index += 1\n",
    "                        continue\n",
    "                final_response['data'] = All_data\n",
    "            except:\n",
    "                print(\"failed\")\n",
    "            return final_response        \n",
    "        \n",
    "    \n",
    "    except requests.Timeout:\n",
    "        final_response[\"Message\"] = \"Request timed out\"\n",
    "        final_response[\"Response\"] = 408\n",
    "        return final_response\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        final_response[\"Message\"] = f\"An error occurred while fetching the linguatools: {e}\"\n",
    "        final_response[\"Response\"] = getattr(e.response, 'status_code', 500)\n",
    "        return final_response\n",
    "    except Exception as e:\n",
    "        final_response[\"Message\"] = f\"An error occurred in code: {e}\"\n",
    "        final_response[\"Response\"] = 504\n",
    "        return final_response\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(path, file_name, data):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(path+file_name, \"w\") as outfile:\n",
    "        \n",
    "        json.dump(data, outfile, indent=4, ensure_ascii=False)\n",
    "        print(f\"Successfully saved: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path, file_name):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(path+file_name, 'r') as openfile:\n",
    "        # Reading from json file\n",
    "        Loaded_file = json.load(openfile)\n",
    "        print(f\"Successfully loaded: {file_name}\")\n",
    "\n",
    "    return Loaded_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runing lingtool page 1 with 5000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://linguatools.info/?page=1&per_page=5000\"\n",
    "linguatools_page1 = scrape_linguatools_translation(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(linguatools_page1[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error in extracting the page 1 : 0\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "for keys in linguatools_page1[\"data\"]:\n",
    "    # print(keys)\n",
    "    if linguatools_page1[\"data\"][keys][\"Message\"] != \"Success\":\n",
    "        print(keys, linguatools_page1[keys][\"Message\"])\n",
    "        index += 1\n",
    "\n",
    "print(f\"Total error in extracting the page 1 : {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved: linguatools_page1.json\n"
     ]
    }
   ],
   "source": [
    "path = \"./data/\" \n",
    "save_json(path, file_name=\"linguatools_page1.json\", data=linguatools_page1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runing lingtool page 2 with 5000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://linguatools.info/?page=2&per_page=5000\"\n",
    "linguatools_page2 = scrape_linguatools_translation(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3678"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(linguatools_page2[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error in extracting the page 2 : 0\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "for keys in linguatools_page2[\"data\"]:\n",
    "    # print(keys)\n",
    "    if linguatools_page2[\"data\"][keys][\"Message\"] != \"Success\":\n",
    "        print(keys, linguatools_page2[keys][\"Message\"])\n",
    "        index += 1\n",
    "\n",
    "print(f\"Total error in extracting the page 2 : {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved: linguatools_page2.json\n"
     ]
    }
   ],
   "source": [
    "path = \"./data/\" \n",
    "save_json(path, file_name=\"linguatools_page2.json\", data=linguatools_page2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the json unicode issues by adding \n",
    "- json.dumps(data, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded: linguatools_page1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./data/\"\n",
    "filename = \"linguatools_page1.json\"\n",
    "json_data = read_json(path, filename)\n",
    "len(json_data[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved: linguatools_page1.json\n"
     ]
    }
   ],
   "source": [
    "save_json(path, filename, json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### page 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded: linguatools_page2.json\n",
      "Successfully saved: linguatools_page2.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = \"linguatools_page2.json\"\n",
    "json_data = read_json(path, filename)\n",
    "len(json_data[\"data\"])\n",
    "save_json(path, filename, json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
